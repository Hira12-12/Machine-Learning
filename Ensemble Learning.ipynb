{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cfbc86-fac9-4228-ae1c-c921edbd6527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 105\n",
      "Testing Samples: 45\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training Samples:\", X_train.shape[0])\n",
    "print(\"Testing Samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ee7937-06ef-4999-ae5c-00baf94f4246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e8c4fc-e532-43e9-a95f-909b1bac3d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffacab1f-b246-4570-8ece-0801eefc1d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecc2b3d-de95-4ccf-b5b5-dbbf4da74d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.5, 2.4, 3.7, 1. ],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.1, 3.5, 1.4, 0.2],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [5.9, 3. , 5.1, 1.8],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [7.1, 3. , 5.9, 2.1]]),\n",
       " array([[6.1, 2.8, 4.7, 1.2],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.4, 3.7, 1.5, 0.2]]),\n",
       " array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
       "        2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,\n",
       "        1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,\n",
       "        2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,\n",
       "        2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2]),\n",
       " array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "        0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d56690c-efca-4216-88cc-64df94bede9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train a simple Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", acc_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9294885b-552e-4b5c-9075-fa3eb4867cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Bagging) Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest (Bagging Technique)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest (Bagging) Accuracy:\", acc_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c0e0b0-7d72-41fb-81ef-2ba0ecb2a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost (Boosting) Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train AdaBoost model\n",
    "ada = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(\"AdaBoost (Boosting) Accuracy:\", acc_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a34085f0-6d49-4f05-8755-23c72c651a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define base models (they will learn separately)\n",
    "base_models = [\n",
    "    ('decision_tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('adaboost', AdaBoostClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "# Define final model (meta learner)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_stack = stack.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
    "print(\"Stacking Classifier Accuracy:\", acc_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f7990e-774b-4bbe-bca5-1db953825971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy\n",
      "0            Decision Tree       1.0\n",
      "1  Random Forest (Bagging)       1.0\n",
      "2      AdaBoost (Boosting)       1.0\n",
      "3      Stacking Classifier       1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a comparison DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest (Bagging)', 'AdaBoost (Boosting)', 'Stacking Classifier'],\n",
    "    'Accuracy': [acc_dt, acc_rf, acc_ada, acc_stack]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cbd0038-857f-41b7-b165-8765d98bcc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in f:\\anacond\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in f:\\anacond\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in f:\\anacond\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9074854a-297b-4da5-9548-daba1ffeb40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in f:\\anacond\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in f:\\anacond\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in f:\\anacond\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in f:\\anacond\\lib\\site-packages (from catboost) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24 in f:\\anacond\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in f:\\anacond\\lib\\site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: plotly in f:\\anacond\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in f:\\anacond\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\anacond\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\anacond\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\anacond\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\anacond\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in f:\\anacond\\lib\\site-packages (from plotly->catboost) (9.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38f22c88-e960-421e-af65-4284a4dec252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBoost & CatBoost installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import catboost\n",
    "print(\"✅ XGBoost & CatBoost installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c38429c3-79b3-439b-99f4-2fd050a9f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (41188, 21)\n",
      "Random Forest Accuracy: 91.33%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 47\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 2️⃣ Boosting - AdaBoost\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m ada \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(\n\u001b[0;32m     48\u001b[0m     base_estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     49\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     50\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     51\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     52\u001b[0m )\n\u001b[0;32m     53\u001b[0m ada\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     54\u001b[0m ada_acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, ada\u001b[38;5;241m.\u001b[39mpredict(X_test))\n",
      "\u001b[1;31mTypeError\u001b[0m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 🎯 Ensemble Learning on Bank Marketing Dataset\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ----------------------------\n",
    "# Load dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Hira Coder\\\\Downloads\\\\bank-additional-full.csv\", sep=';')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df\n",
    "# ----------------------------\n",
    "# Data Preprocessing\n",
    "# ----------------------------\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split into features & target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣ Bagging - Random Forest\n",
    "# ----------------------------\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "print(f\"Random Forest Accuracy: {rf_acc*100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2️⃣ Boosting - AdaBoost\n",
    "# ----------------------------\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "ada_acc = accuracy_score(y_test, ada.predict(X_test))\n",
    "print(f\"AdaBoost Accuracy: {ada_acc*100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ Boosting - XGBoost\n",
    "# ----------------------------\n",
    "xgb = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
    "print(f\"XGBoost Accuracy: {xgb_acc*100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ Boosting - CatBoost\n",
    "# ----------------------------\n",
    "cat = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=5, verbose=0)\n",
    "cat.fit(X_train, y_train)\n",
    "cat_acc = accuracy_score(y_test, cat.predict(X_test))\n",
    "print(f\"CatBoost Accuracy: {cat_acc*100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ Stacking Ensemble\n",
    "# ----------------------------\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, random_state=42)),\n",
    "    ('cat', CatBoostClassifier(iterations=100, verbose=0, random_state=42))\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "stack_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)\n",
    "stack_model.fit(X_train, y_train)\n",
    "stack_acc = accuracy_score(y_test, stack_model.predict(X_test))\n",
    "print(f\"Stacking Accuracy: {stack_acc*100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 🔍 Summary of Results\n",
    "# ----------------------------\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(f\"Random Forest  : {rf_acc*100:.2f}%\")\n",
    "print(f\"AdaBoost       : {ada_acc*100:.2f}%\")\n",
    "print(f\"XGBoost        : {xgb_acc*100:.2f}%\")\n",
    "print(f\"CatBoost       : {cat_acc*100:.2f}%\")\n",
    "print(f\"Stacking       : {stack_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85a25f79-3c2f-48be-bec4-d1095935112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 🎯 Ensemble Learning on Bank Marketing Dataset\n",
    "# ==============================\n",
    "\n",
    "# Install if missing\n",
    "# !pip install xgboost\n",
    "# !pip install catboost\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e388349-a781-4528-a4b4-465c2e3d4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Loaded Successfully!\n",
      "Shape: (41188, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y       no      no   no   \n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...         1    999         0   \n",
       "1      telephone   may         mon  ...         1    999         0   \n",
       "2      telephone   may         mon  ...         1    999         0   \n",
       "3      telephone   may         mon  ...         1    999         0   \n",
       "4      telephone   may         mon  ...         1    999         0   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...         1    999         0   \n",
       "41184   cellular   nov         fri  ...         1    999         0   \n",
       "41185   cellular   nov         fri  ...         2    999         0   \n",
       "41186   cellular   nov         fri  ...         1    999         0   \n",
       "41187   cellular   nov         fri  ...         3    999         1   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41187      failure         -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed    y  \n",
       "0           5191.0   no  \n",
       "1           5191.0   no  \n",
       "2           5191.0   no  \n",
       "3           5191.0   no  \n",
       "4           5191.0   no  \n",
       "...            ...  ...  \n",
       "41183       4963.6  yes  \n",
       "41184       4963.6   no  \n",
       "41185       4963.6   no  \n",
       "41186       4963.6  yes  \n",
       "41187       4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Load dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Hira Coder\\\\Downloads\\\\bank-additional-full.csv\", sep=';')\n",
    "\n",
    "print(\"✅ Dataset Loaded Successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0b989c9-55e5-45c3-a18e-63815a255076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Preprocessing Done!\n",
      "Training Data Shape: (32950, 20)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Data Preprocessing\n",
    "# ----------------------------\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert all categorical columns to numeric\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split data into features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ Data Preprocessing Done!\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f76d5993-bd86-434b-aaec-760f578f9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌳 Random Forest Accuracy: 91.33%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1️⃣ Bagging - Random Forest\n",
    "# ----------------------------\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "print(f\"🌳 Random Forest Accuracy: {rf_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baccce0b-a68e-42d8-9be0-820730b2a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ XGBoost Accuracy: 91.89%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3️⃣ Boosting - XGBoost\n",
    "# ----------------------------\n",
    "xgb = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
    "\n",
    "print(f\"⚡ XGBoost Accuracy: {xgb_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9724dcc8-aec1-4097-b40c-584efb4c609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ CatBoost Accuracy: 92.01%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4️⃣ Boosting - CatBoost\n",
    "# ----------------------------\n",
    "cat = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=5, verbose=0)\n",
    "cat.fit(X_train, y_train)\n",
    "cat_acc = accuracy_score(y_test, cat.predict(X_test))\n",
    "\n",
    "print(f\"⚡ CatBoost Accuracy: {cat_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "279bb80c-95b4-4eec-81c4-7302169f4ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ AdaBoost Accuracy: 90.75%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2️⃣ Boosting - AdaBoost\n",
    "# ----------------------------\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "ada_acc = accuracy_score(y_test, ada.predict(X_test))\n",
    "\n",
    "print(f\"⚡ AdaBoost Accuracy: {ada_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f67c11ab-4676-4e16-b585-99e1c6b3a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Stacking Accuracy: 91.61%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5️⃣ Stacking Ensemble\n",
    "# ----------------------------\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, random_state=42)),\n",
    "    ('cat', CatBoostClassifier(iterations=100, verbose=0, random_state=42))\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner\n",
    ")\n",
    "\n",
    "stack_model.fit(X_train, y_train)\n",
    "stack_acc = accuracy_score(y_test, stack_model.predict(X_test))\n",
    "\n",
    "print(f\"🧠 Stacking Accuracy: {stack_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e3dd20d-ca95-49ad-8a77-76015daddbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏁 Model Performance Summary:\n",
      "Random Forest  : 91.33%\n",
      "AdaBoost       : 90.75%\n",
      "XGBoost        : 91.89%\n",
      "CatBoost       : 92.01%\n",
      "Stacking       : 91.61%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 🔍 Summary of Results\n",
    "# ----------------------------\n",
    "print(\"\\n🏁 Model Performance Summary:\")\n",
    "print(f\"Random Forest  : {rf_acc*100:.2f}%\")\n",
    "print(f\"AdaBoost       : {ada_acc*100:.2f}%\")\n",
    "print(f\"XGBoost        : {xgb_acc*100:.2f}%\")\n",
    "print(f\"CatBoost       : {cat_acc*100:.2f}%\")\n",
    "print(f\"Stacking       : {stack_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021e0d2-597a-4403-9bfd-d0b6c07ad45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
